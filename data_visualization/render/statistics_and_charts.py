from calculation.retirement import *
from data_visualization.tool.func import *


def get_1_year_age_and_gender_dataframe(year: str, area: str = None, school: str = None,
                                        period: str = None) -> DataFrameContainer:
    """
    æ ¹æ®å¹´ä»½ç”Ÿæˆåˆ—ä¸ºå¹´é¾„ï¼Œè¡Œä¸ºæ€§åˆ«çš„dataframe\n
    data: äºŒç»´dataframeï¼ŒåŒ…å«æ€§åˆ«å’Œå¹´é¾„\n
    sum: ä¸€ç»´dataframeï¼ŒåŒ…å«å¹´é¾„å’Œäººæ•°æ€»å’Œ
    :param year: æŸ¥è¯¢çš„å¹´ä»½ï¼ˆå¿…å¡«ï¼‰
    :param area: æŸ¥è¯¢çš„ç‰‡é•‡ï¼ˆé€‰å¡«ï¼‰
    :param school: æŸ¥è¯¢çš„å­¦æ ¡ï¼ˆé€‰å¡«ï¼‰
    :param period: æŸ¥è¯¢çš„å­¦æ®µï¼ˆé€‰å¡«ï¼‰
    :return:
    """

    container = DataFrameContainer()

    df_dict = {"ç”·": {}, "å¥³": {}}  # ä½¿ç”¨åµŒå¥—å­—å…¸ä¿å­˜æ•°æ®ï¼Œå¤–å±‚ä¸ºæ€§åˆ«è¡Œï¼Œå†…å±‚ä¸ºå¹´é¾„åˆ—
    ages = set()  # ç”¨äºæ£€æŸ¥age_dictä¸­æ˜¯å¦æœ‰å¯¹åº”çš„å¹´é¾„

    min_age = 1000
    max_age = -1

    id_list = execute_sql_sentence(
        sentence=f'select "èº«ä»½è¯å·", "æ€§åˆ«" from teacher_data_0_{year} where 1{f' and "åŒºåŸŸ" = "{area}"' if area is not None else ''}{f' and "æ ¡å" = "{school}"' if school is not None else ''}{f' and "ä»»æ•™å­¦æ®µ" = "{period}"' if period is not None else ''}'
    )

    for item in id_list:

        age = str(get_age_from_citizen_id(citizen_id=item[0], year=year))

        min_age = int(age) if int(age) < min_age else min_age
        max_age = int(age) if int(age) > max_age else max_age

        if age not in ages:

            for gender in ["ç”·", "å¥³"]:
                df_dict[gender][age] = 0

        df_dict[item[1]][age] += 1

        ages.add(age)

    for age in range(min_age, max_age):

        if str(age) not in df_dict["ç”·"].keys():
            df_dict["ç”·"][str(age)] = 0

        if str(age) not in df_dict["å¥³"].keys():
            df_dict["å¥³"][str(age)] = 0

    container.add_dataframe(name="data", df=sort_dataframe_columns(df=convert_dict_to_dataframe(d=df_dict)))

    df = pd.DataFrame(sort_dataframe_columns(df=convert_dict_to_dataframe(d=df_dict)).sum()).T
    df.index = ["åˆè®¡"]

    container.add_dataframe("sum", df=df)

    return container


def get_1_year_grad_school_dataframe(year: str, area: str = None, school: str = None,
                                     period: str = None) -> DataFrameContainer:
    """
    æ ¹æ®å¹´ä»½å¤šä¸ªåŒ…å«é™¢æ ¡ååŠå…¶é¢‘ç‡çš„dataframe\n
    df_985:985é™¢æ ¡ååŠå…¶æ•°é‡\n
    df_nettp:å›½ä¼˜è®¡åˆ’é™¢æ ¡ååŠå…¶æ•°é‡\n
    df_affiliate:éƒ¨å±å¸ˆèŒƒé™¢æ ¡ååŠå…¶æ•°é‡\n
    df_211:211é™¢æ ¡ååŠå…¶æ•°é‡\n
    :param year: æŸ¥è¯¢çš„å¹´ä»½ï¼ˆå¿…å¡«ï¼‰
    :param area: æŸ¥è¯¢çš„ç‰‡é•‡ï¼ˆé€‰å¡«ï¼‰
    :param school: æŸ¥è¯¢çš„å­¦æ ¡ï¼ˆé€‰å¡«ï¼‰
    :param period: æŸ¥è¯¢çš„å­¦æ®µï¼ˆé€‰å¡«ï¼‰
    :return:
    """
    container = DataFrameContainer()

    try:
        container.add_dataframe(
            name="df_985",
            df=pd.Series(
                dict(
                    execute_sql_sentence(
                        sentence=f'select "å‚åŠ å·¥ä½œå‰æ¯•ä¸šé™¢æ ¡ä»£ç ",count(*) from teacher_data_0_{year} where "å‚åŠ å·¥ä½œå‰æ¯•ä¸šé™¢æ ¡ä»£ç " in ({', '.join([f'"{code}"' for code in get_school_codes()["985"]])}){f' and "åŒºåŸŸ" = "{area}"' if area is not None else ''}{f' and "æ ¡å" = "{school}"' if school is not None else ''}{f' and "ä»»æ•™å­¦æ®µ" = "{period}"' if period is not None else ''} and "å‚åŠ å·¥ä½œå‰å­¦å†" in ("æœ¬ç§‘", "ç¡•å£«ç ”ç©¶ç”Ÿ", "åšå£«ç ”ç©¶ç”Ÿ") group by "å‚åŠ å·¥ä½œå‰æ¯•ä¸šé™¢æ ¡ä»£ç "'
                    )
                )
            )
            .nlargest(20).to_frame()
            .rename(
                index={
                    key: value[0] for key, value in load_json_data(folder="source", file_name="é™¢æ ¡ä»£ç ").items()
                },
                columns={0: "äººæ•°"}
            )
            .rename_axis(["985é™¢æ ¡"])
        )

    except TypeError as e:
        if "Cannot use method 'nlargest' with dtype object" in str(e):
            st.toast(f'æ— 985é™¢æ ¡æ¯•ä¸šç”Ÿ', icon="ğŸ˜Ÿ")
            container.add_dataframe(
                name="df_985",
                df=pd.DataFrame(data=["0"], columns=["äººæ•°"], index=["æ— "]).rename_axis(["985é™¢æ ¡"])
            )
        else:
            print(e)

    try:
        container.add_dataframe(
            name="df_nettp",
            df=pd.Series(
                dict(
                    execute_sql_sentence(
                        sentence=f'select "å‚åŠ å·¥ä½œå‰æ¯•ä¸šé™¢æ ¡ä»£ç ",count(*) from teacher_data_0_{year} where "å‚åŠ å·¥ä½œå‰æ¯•ä¸šé™¢æ ¡ä»£ç " in ({', '.join([f'"{code}"' for code in get_school_codes()["å›½ä¼˜è®¡åˆ’"]])}){f' and "åŒºåŸŸ" = "{area}"' if area is not None else ''}{f' and "æ ¡å" = "{school}"' if school is not None else ''}{f' and "ä»»æ•™å­¦æ®µ" = "{period}"' if period is not None else ''} and "å‚åŠ å·¥ä½œå‰å­¦å†" in ("æœ¬ç§‘", "ç¡•å£«ç ”ç©¶ç”Ÿ", "åšå£«ç ”ç©¶ç”Ÿ") group by "å‚åŠ å·¥ä½œå‰æ¯•ä¸šé™¢æ ¡ä»£ç "'
                    )
                )
            )
            .nlargest(20).to_frame()
            .rename(
                index={
                    key: value[0] for key, value in load_json_data(folder="source", file_name="é™¢æ ¡ä»£ç ").items()
                },
                columns={0: "äººæ•°"}
            )
            .rename_axis(["å›½ä¼˜è®¡åˆ’é™¢æ ¡"])
        )

    except TypeError as e:
        if "Cannot use method 'nlargest' with dtype object" in str(e):
            st.toast(f'æ— å›½ä¼˜è®¡åˆ’é™¢æ ¡æ¯•ä¸šç”Ÿ', icon="ğŸ˜Ÿ")
            container.add_dataframe(
                name="df_nettp",
                df=pd.DataFrame(data=["0"], columns=["äººæ•°"], index=["æ— "]).rename_axis(["å›½ä¼˜è®¡åˆ’é™¢æ ¡"])
            )
        else:
            print(e)

    try:
        container.add_dataframe(
            name="df_affiliate",
            df=pd.Series(
                dict(
                    execute_sql_sentence(
                        sentence=f'select "å‚åŠ å·¥ä½œå‰æ¯•ä¸šé™¢æ ¡ä»£ç ",count(*) from teacher_data_0_{year} where "å‚åŠ å·¥ä½œå‰æ¯•ä¸šé™¢æ ¡ä»£ç " in ({', '.join([f'"{code}"' for code in get_school_codes()["éƒ¨å±å¸ˆèŒƒ"]])}){f' and "åŒºåŸŸ" = "{area}"' if area is not None else ''}{f' and "æ ¡å" = "{school}"' if school is not None else ''}{f' and "ä»»æ•™å­¦æ®µ" = "{period}"' if period is not None else ''} and "å‚åŠ å·¥ä½œå‰å­¦å†" in ("æœ¬ç§‘", "ç¡•å£«ç ”ç©¶ç”Ÿ", "åšå£«ç ”ç©¶ç”Ÿ") group by "å‚åŠ å·¥ä½œå‰æ¯•ä¸šé™¢æ ¡ä»£ç "'
                    )
                )
            )
            .nlargest(20).to_frame()
            .rename(
                index={
                    key: value[0] for key, value in load_json_data(folder="source", file_name="é™¢æ ¡ä»£ç ").items()
                },
                columns={0: "äººæ•°"}
            )
            .rename_axis(["éƒ¨å±å¸ˆèŒƒé™¢æ ¡"])
        )

    except TypeError as e:
        if "Cannot use method 'nlargest' with dtype object" in str(e):
            st.toast(f'æ— éƒ¨å±å¸ˆèŒƒé™¢æ ¡æ¯•ä¸šç”Ÿ', icon="ğŸ˜Ÿ")
            container.add_dataframe(
                name="df_affiliate",
                df=pd.DataFrame(data=["0"], columns=["äººæ•°"], index=["æ— "]).rename_axis(["éƒ¨å±å¸ˆèŒƒé™¢æ ¡"])
            )
        else:
            print(e)

    try:
        container.add_dataframe(
            name="df_211",
            df=pd.Series(
                dict(
                    execute_sql_sentence(
                        sentence=f'select "å‚åŠ å·¥ä½œå‰æ¯•ä¸šé™¢æ ¡ä»£ç ",count(*) from teacher_data_0_{year} where "å‚åŠ å·¥ä½œå‰æ¯•ä¸šé™¢æ ¡ä»£ç " in ({', '.join([f'"{code}"' for code in get_school_codes()["211"]])}){f' and "åŒºåŸŸ" = "{area}"' if area is not None else ''}{f' and "æ ¡å" = "{school}"' if school is not None else ''}{f' and "ä»»æ•™å­¦æ®µ" = "{period}"' if period is not None else ''} and "å‚åŠ å·¥ä½œå‰å­¦å†" in ("æœ¬ç§‘", "ç¡•å£«ç ”ç©¶ç”Ÿ", "åšå£«ç ”ç©¶ç”Ÿ") group by "å‚åŠ å·¥ä½œå‰æ¯•ä¸šé™¢æ ¡ä»£ç "'
                    )
                )
            )
            .nlargest(20).to_frame()
            .rename(
                index={
                    key: value[0] for key, value in load_json_data(folder="source", file_name="é™¢æ ¡ä»£ç ").items()
                },
                columns={0: "äººæ•°"}
            )
            .rename_axis(["211é™¢æ ¡"])
        )

    except TypeError as e:
        if "Cannot use method 'nlargest' with dtype object" in str(e):
            st.toast(f'æ— 211é™¢æ ¡æ¯•ä¸šç”Ÿ', icon="ğŸ˜Ÿ")
            container.add_dataframe(
                name="df_211",
                df=pd.DataFrame(data=["0"], columns=["äººæ•°"], index=["æ— "]).rename_axis(["211é™¢æ ¡"])
            )
        else:
            print(e)

    container.add_dataframe(
        name="df_all",
        df=pd.Series(
            dict(
                execute_sql_sentence(
                    sentence=f'select "å‚åŠ å·¥ä½œå‰æ¯•ä¸šé™¢æ ¡ä»£ç ",count(*) from teacher_data_0_{year} where "å‚åŠ å·¥ä½œå‰æ¯•ä¸šé™¢æ ¡ä»£ç " not in ({', '.join([f'"{code}"' for code in ["æ— ", "51161", "51315"]])}){f' and "åŒºåŸŸ" = "{area}"' if area is not None else ''}{f' and "æ ¡å" = "{school}"' if school is not None else ''}{f' and "ä»»æ•™å­¦æ®µ" = "{period}"' if period is not None else ''} and "å‚åŠ å·¥ä½œå‰å­¦å†" in ("æœ¬ç§‘", "ç¡•å£«ç ”ç©¶ç”Ÿ", "åšå£«ç ”ç©¶ç”Ÿ") group by "å‚åŠ å·¥ä½œå‰æ¯•ä¸šé™¢æ ¡ä»£ç "'
                )
            )
        )
        .nlargest(100).to_frame()
        .rename(
            index={
                key: value[0] for key, value in load_json_data(folder="source", file_name="é™¢æ ¡ä»£ç ").items()
            },
            columns={0: "äººæ•°"}
        )
        .rename_axis(["æ‰€æœ‰é™¢æ ¡"])
    )

    return container


def get_1_year_discipline_and_gender_dataframe(year: str, area: str = None, school: str = None,
                                               period: str = None) -> DataFrameContainer:
    """
    æ ¹æ®å¹´ä»½ç”Ÿæˆåˆ—ä¸ºå­¦ç§‘ï¼Œè¡Œä¸ºæ€§åˆ«çš„dataframe
    :param year: æŸ¥è¯¢çš„å¹´ä»½ï¼ˆå¿…å¡«ï¼‰
    :param area: æŸ¥è¯¢çš„ç‰‡é•‡ï¼ˆé€‰å¡«ï¼‰
    :param school: æŸ¥è¯¢çš„å­¦æ ¡ï¼ˆé€‰å¡«ï¼‰
    :param period: æŸ¥è¯¢çš„å­¦æ®µï¼ˆé€‰å¡«ï¼‰
    :return:
    """

    container = DataFrameContainer()

    df_dict = {"ç”·": {}, "å¥³": {}}  # ä½¿ç”¨åµŒå¥—å­—å…¸ä¿å­˜æ•°æ®ï¼Œå¤–å±‚ä¸ºæ€§åˆ«è¡Œï¼Œå†…å±‚ä¸ºå­¦ç§‘åˆ—

    discipline_list = del_tuple_in_list(
        execute_sql_sentence(
            sentence=f'select "ä¸»æ•™å­¦ç§‘", count(*) from teacher_data_0_{year} where "ä¸»æ•™å­¦ç§‘" != "æ— "{f' and "åŒºåŸŸ" = "{area}"' if area is not None else ''}{f' and "æ ¡å" = "{school}"' if school is not None else ''}{f' and "ä»»æ•™å­¦æ®µ" = "{period}"' if period is not None else ''} group by "ä¸»æ•™å­¦ç§‘" order by count(*) desc limit 16'
        )
    )

    for discipline in discipline_list:
        data = execute_sql_sentence(
            sentence=f'select "æ€§åˆ«", count(*) from teacher_data_0_{year} where "ä¸»æ•™å­¦ç§‘" = "{discipline}"{f' and "åŒºåŸŸ" = "{area}"' if area is not None else ''}{f' and "æ ¡å" = "{school}"' if school is not None else ''}{f' and "ä»»æ•™å­¦æ®µ" = "{period}"' if period is not None else ''} group by "æ€§åˆ«"'
        )

        for item in data:
            df_dict[item[0]][discipline] = item[1]

    container.add_dataframe(name="data", df=convert_dict_to_dataframe(d=df_dict))
    df = pd.DataFrame(convert_dict_to_dataframe(d=df_dict).sum()).T
    df.index = ["åˆè®¡"]
    container.add_dataframe(name="sum", df=df)

    return container


def get_1_year_and_multi_areas_or_schools_teacher_0_age_dataframe(year: str, area_list: list[str] = None,
                                                                  school_list: list[str] = None,
                                                                  period: str = None) -> DataFrameContainer:
    """
    æ ¹æ®ç»™å®šçš„èŒƒå›´åˆ—è¡¨ç”Ÿæˆå•ä¸ªå¹´é¾„ç»Ÿè®¡dataframeï¼Œæ”¾ç½®åœ¨containerä¸­\n
    age_and_locationï¼šæ‰€æœ‰æ•°æ®ï¼Œåˆ—ä¸ºå¹´é¾„ï¼Œè¡Œä¸ºç‰‡é•‡æˆ–å­¦æ ¡\n
    age_percentage_and_location: æ‰€æœ‰å¹´é¾„å ç‰‡é•‡å æ¯”ï¼Œåˆ—ä¸ºå¹´é¾„ï¼Œè¡Œä¸ºç‰‡é•‡
    :param year: æŸ¥è¯¢çš„å¹´ä»½
    :param area_list: æŸ¥è¯¢çš„ç‰‡é•‡åˆ—è¡¨
    :param school_list: æŸ¥è¯¢çš„å­¦æ ¡åˆ—è¡¨
    :param period: ä»»æ•™å­¦æ®µ
    :return: DataFrameContainerï¼ŒåŒ…å«è‹¥å¹²ä¸ªdataframe
    """
    container = DataFrameContainer()

    min_age = 1000
    max_age = -1

    df1 = {}  # ä½¿ç”¨åµŒå¥—å­—å…¸ä¿å­˜æ•°æ®ï¼Œå¤–å±‚ä¸ºå¹´ä»½è¡Œï¼Œå†…å±‚ä¸ºå¹´é¾„åˆ—
    df1.update({location: {} for location in (area_list if area_list is not None else school_list)})  # åˆå§‹åŒ–è¯¥å¹´ä»½çš„å­å­—å…¸

    df2_values_sum = {}
    df2_values_sum.update(
        {a: 0 for a in (area_list if area_list is not None else school_list)})  # è®¡ç®—æ¯ä¸€ä¸ªèŒƒå›´å½“å¹´çš„æ€»äººæ•°ï¼Œç”¨äºè®¡ç®—æŸä¸ªå¹´é¾„çš„å æ¯”

    id_list = execute_sql_sentence(
        sentence=f'select "èº«ä»½è¯å·", "{'åŒºåŸŸ' if area_list is not None else 'æ ¡å'}" from teacher_data_0_{year} where "{'åŒºåŸŸ' if area_list is not None else 'æ ¡å'}" in ({', '.join([f'"{location}"' for location in (area_list if area_list is not None else school_list)])}){f' and "ä»»æ•™å­¦æ®µ" = "{period}"' if period is not None else ''}'
    )

    """
    df_dict:{
    "æ°¸å¹³":{
        25:100,
        26:200
        },
    "çŸ³äº•"ï¼š{
        25ï¼š50ï¼Œ
        24ï¼š100
        }
    }
    """

    for item in id_list:

        age = str(get_age_from_citizen_id(citizen_id=item[0], year=year))

        min_age = int(age) if int(age) < min_age else min_age
        max_age = int(age) if int(age) > max_age else max_age

        if age == "0":
            print_color_text(item[0])
            print_color_text(year)

        if age in df1[item[1]].keys():
            df1[item[1]][age] += 1
        else:
            df1[item[1]][age] = 1

        df2_values_sum[item[1]] += 1

    for location in (area_list if area_list is not None else school_list):
        for age in range(min_age, max_age + 1):

            if str(age) not in df1[location].keys():
                df1[location][str(age)] = 0

    df2 = df1
    df1 = sort_dataframe_columns(df=convert_dict_to_dataframe(d=df1))
    df1.fillna(value=0, inplace=True)
    container.add_dataframe(name="age_and_location", df=df1)

    for location in (area_list if area_list is not None else school_list):
        for age in df2[location].keys():
            df2[location][age] = round(number=100 * float(
                (df2[location][age] / df2_values_sum[location] if df2_values_sum[location] != 0 else 0)), ndigits=1)

    df2 = sort_dataframe_columns(df=convert_dict_to_dataframe(d=df2))
    df2.fillna(value=0, inplace=True)
    container.add_dataframe(name="age_percentage_and_location", df=df2)

    return container


def get_1_year_and_multi_areas_or_schools_teacher_0_edu_bg_dataframe(year: str, area_list: list[str] = None,
                                                                     school_list: list[str] = None,
                                                                     period: str = None) -> DataFrameContainer:
    """
    æ ¹æ®ç‰‡é•‡åˆ—è¡¨ç”Ÿæˆå•ä¸ªå­¦å†ç»Ÿè®¡dataframeï¼Œæ”¾ç½®åœ¨containerä¸­\n
    edu_bg_and_locationï¼šæ‰€æœ‰æ•°æ®ï¼Œåˆ—ä¸ºå­¦å†ï¼Œè¡Œä¸ºèŒƒå›´\n
    edu_bg_percentage_and_location: æ‰€æœ‰å­¦å†å èŒƒå›´å æ¯”ï¼Œåˆ—ä¸ºå­¦å†ï¼Œè¡Œä¸ºèŒƒå›´
    :param year: æŸ¥è¯¢çš„å¹´ä»½
    :param area_list: æŸ¥è¯¢çš„ç‰‡é•‡åˆ—è¡¨
    :param school_list: æŸ¥è¯¢çš„å­¦æ ¡åˆ—è¡¨
    :param period: ä»»æ•™å­¦æ®µ
    :return: DataFrameContainerï¼ŒåŒ…å«è‹¥å¹²ä¸ªdataframe
    """
    container = DataFrameContainer()

    df1 = {}  # ä½¿ç”¨åµŒå¥—å­—å…¸ä¿å­˜æ•°æ®ï¼Œå¤–å±‚ä¸ºå¹´ä»½è¡Œï¼Œå†…å±‚ä¸ºå­¦å†åˆ—
    """
    df_dict:{
    "æ°¸å¹³":{
        "æœ¬ç§‘":100,
        "ç¡•å£«ç ”ç©¶ç”Ÿ":200
        },
    "çŸ³äº•"ï¼š{
        "æœ¬ç§‘"ï¼š50ï¼Œ
        "ç¡•å£«ç ”ç©¶ç”Ÿ"ï¼š100
        }
    }
    """
    df1.update({location: {} for location in (area_list if area_list is not None else school_list)})  # åˆå§‹åŒ–è¯¥å¹´ä»½çš„å­å­—å…¸

    df2_values_sum = {}
    df2_values_sum.update({location: {} for location in
                           (area_list if area_list is not None else school_list)})  # è®¡ç®—æ¯ä¸€ä¸ªèŒƒå›´å½“å¹´çš„æ€»äººæ•°ï¼Œç”¨äºè®¡ç®—æŸä¸ªå­¦å†çš„å æ¯”

    edu_bg_list = execute_sql_sentence(
        sentence=f'select "æœ€é«˜å­¦å†", "{'åŒºåŸŸ' if area_list is not None else 'æ ¡å'}", count(*) from teacher_data_0_{year} where "{'åŒºåŸŸ' if area_list is not None else 'æ ¡å'}" in ({', '.join([f'"{location}"' for location in (area_list if area_list is not None else school_list)])}){f' and "ä»»æ•™å­¦æ®µ" = "{period}" ' if period is not None else ' '}and "æœ€é«˜å­¦å†" in ({', '.join([f'"{bg}"' for bg in get_edu_bg_list()])}) group by "æœ€é«˜å­¦å†", "{'åŒºåŸŸ' if area_list is not None else 'æ ¡å'}"'
    )

    count_list = execute_sql_sentence(
        sentence=f'select "{'åŒºåŸŸ' if area_list is not None else 'æ ¡å'}", count(*) from teacher_data_0_{year} where "{'åŒºåŸŸ' if area_list is not None else 'æ ¡å'}" in ({', '.join([f'"{location}"' for location in (area_list if area_list is not None else school_list)])}){f' and "ä»»æ•™å­¦æ®µ" = "{period}" ' if period is not None else ' '}group by "{'åŒºåŸŸ' if area_list is not None else 'æ ¡å'}"'
    )

    for item in edu_bg_list:
        df1[item[1]][item[0]] = item[2]

        df2_values_sum[item[1]][item[0]] = round(
            number=100 * float(item[2] / list(x[1] for x in count_list if x[0] == item[1])[0]),
            ndigits=1
        )

    df1 = convert_dict_to_dataframe(d=df1).reindex(columns=get_edu_bg_list())
    df1.fillna(value=0, inplace=True)
    container.add_dataframe(name="edu_bg_and_location", df=df1)

    df2 = convert_dict_to_dataframe(d=df2_values_sum).reindex(columns=get_edu_bg_list())
    df2.fillna(value=0, inplace=True)
    container.add_dataframe(name="edu_bg_percentage_and_location", df=df2)

    return container


def get_1_year_and_multi_areas_or_schools_teacher_0_vocational_level_detail_dataframe(year: str,
                                                                                      area_list: list[str] = None,
                                                                                      school_list: list[str] = None,
                                                                                      period: str = None) -> DataFrameContainer:
    """
    æ ¹æ®èŒƒå›´åˆ—è¡¨ç”Ÿæˆå•ä¸ªä¸“æŠ€ç­‰çº§ç»Ÿè®¡dataframeï¼Œæ”¾ç½®åœ¨containerä¸­\n
    vocational_level_detail_and_locationï¼šæ‰€æœ‰æ•°æ®ï¼Œåˆ—ä¸ºä¸“æŠ€ç­‰çº§ï¼Œè¡Œä¸ºèŒƒå›´\n
    vocational_level_detail_percentage_and_location: æ‰€æœ‰ä¸“æŠ€ç­‰çº§å èŒƒå›´å æ¯”ï¼Œåˆ—ä¸ºä¸“æŠ€ç­‰çº§ï¼Œè¡Œä¸ºèŒƒå›´
    :param year: æŸ¥è¯¢çš„å¹´ä»½
    :param area_list: æŸ¥è¯¢çš„ç‰‡é•‡åˆ—è¡¨
    :param school_list: æŸ¥è¯¢çš„å­¦æ ¡åˆ—è¡¨
    :param period: ä»»æ•™å­¦æ®µ
    :return: DataFrameContainerï¼ŒåŒ…å«è‹¥å¹²ä¸ªdataframe
    """
    container = DataFrameContainer()

    df1 = {}
    df1.update({location: {} for location in (area_list if area_list is not None else school_list)})  # åˆå§‹åŒ–è¯¥å¹´ä»½çš„å­å­—å…¸

    df2_values_sum = {}
    df2_values_sum.update({location: {} for location in (area_list if area_list is not None else school_list)})

    vocational_level_detail_list = execute_sql_sentence(
        sentence=f'select "ä¸“ä¸šæŠ€æœ¯å²—ä½", "{'åŒºåŸŸ' if area_list is not None else 'æ ¡å'}", count(*) from teacher_data_0_{year} where "{'åŒºåŸŸ' if area_list is not None else 'æ ¡å'}" in ({', '.join([f'"{location}"' for location in (area_list if area_list is not None else school_list)])}){f' and "ä»»æ•™å­¦æ®µ" = "{period}" ' if period is not None else ' '}and "ä¸“ä¸šæŠ€æœ¯å²—ä½" in ({', '.join([f'"{d}"' for d in get_vocational_level_detail_list()])}) group by "ä¸“ä¸šæŠ€æœ¯å²—ä½", "{'åŒºåŸŸ' if area_list is not None else 'æ ¡å'}"'
    )

    count_list = execute_sql_sentence(
        sentence=f'select "{'åŒºåŸŸ' if area_list is not None else 'æ ¡å'}", count(*) from teacher_data_0_{year} where "{'åŒºåŸŸ' if area_list is not None else 'æ ¡å'}" in ({', '.join([f'"{location}"' for location in (area_list if area_list is not None else school_list)])}){f' and "ä»»æ•™å­¦æ®µ" = "{period}" ' if period is not None else ' '}group by "{'åŒºåŸŸ' if area_list is not None else 'æ ¡å'}"'
    )

    for item in vocational_level_detail_list:
        df1[item[1]][item[0]] = item[2]

        df2_values_sum[item[1]][item[0]] = round(
            number=100 * float(item[2] / list(x[1] for x in count_list if x[0] == item[1])[0]),
            ndigits=1
        )

    df1 = convert_dict_to_dataframe(d=df1)
    df1.fillna(value=0, inplace=True)
    df1 = df1.reindex(columns=shorten_vocational_level_detail_dict()).rename(
        columns=shorten_vocational_level_detail_dict())
    container.add_dataframe(name="vocational_level_detail_and_location", df=df1)

    df2 = convert_dict_to_dataframe(d=df2_values_sum)
    df2.fillna(value=0, inplace=True)
    df2 = df2.reindex(columns=shorten_vocational_level_detail_dict()).rename(
        columns=shorten_vocational_level_detail_dict())
    container.add_dataframe(name="vocational_level_detail_percentage_and_location", df=df2)

    return container


def get_1_year_and_multi_areas_or_schools_teacher_0_discipline_dataframe(year: str,
                                                                         area_list: list[str] = None,
                                                                         school_list: list[str] = None,
                                                                         period: str = None) -> DataFrameContainer:
    """
    æ ¹æ®èŒƒå›´åˆ—è¡¨ç”Ÿæˆå­¦ç§‘äººæ•°ç»Ÿè®¡dataframeï¼Œæ”¾ç½®åœ¨containerä¸­\n
    discipline_and_locationï¼šæ‰€æœ‰æ•°æ®ï¼Œåˆ—ä¸ºå­¦ç§‘ï¼Œè¡Œä¸ºèŒƒå›´\n
    discipline_percentage_and_location: æ‰€æœ‰å­¦ç§‘å èŒƒå›´å æ¯”ï¼Œåˆ—ä¸ºå­¦ç§‘ï¼Œè¡Œä¸ºèŒƒå›´
    :param year: æŸ¥è¯¢çš„å¹´ä»½
    :param area_list: æŸ¥è¯¢çš„ç‰‡é•‡åˆ—è¡¨
    :param school_list: æŸ¥è¯¢çš„å­¦æ ¡åˆ—è¡¨
    :param period: ä»»æ•™å­¦æ®µ
    :return: DataFrameContainerï¼ŒåŒ…å«è‹¥å¹²ä¸ªdataframe
    """
    container = DataFrameContainer()

    df1 = {}  # ä½¿ç”¨åµŒå¥—å­—å…¸ä¿å­˜æ•°æ®ï¼Œå¤–å±‚ä¸ºå¹´ä»½è¡Œï¼Œå†…å±‚ä¸ºå­¦ç§‘åˆ—
    df1.update({location: {} for location in (area_list if area_list is not None else school_list)})  # åˆå§‹åŒ–è¯¥å¹´ä»½çš„å­å­—å…¸

    df2_values_sum = {}
    df2_values_sum.update({location: {} for location in
                           (area_list if area_list is not None else school_list)})  # è®¡ç®—æ¯ä¸€ä¸ªèŒƒå›´å½“å¹´çš„æ€»äººæ•°ï¼Œç”¨äºè®¡ç®—æŸä¸ªå­¦ç§‘çš„å æ¯”

    discipline_detail_list = execute_sql_sentence(
        sentence=f'select "ä¸»æ•™å­¦ç§‘", "{'åŒºåŸŸ' if area_list is not None else 'æ ¡å'}", count(*) from teacher_data_0_{year} where "{'åŒºåŸŸ' if area_list is not None else 'æ ¡å'}" in ({', '.join([f'"{location}"' for location in (area_list if area_list is not None else school_list)])}){f' and "ä»»æ•™å­¦æ®µ" = "{period}" ' if period is not None else ' '}and "ä¸»æ•™å­¦ç§‘" in ({', '.join([f'"{d}"' for d in get_discipline_list()])}) group by "ä¸»æ•™å­¦ç§‘", "{'åŒºåŸŸ' if area_list is not None else 'æ ¡å'}"'
    )

    count_list = execute_sql_sentence(
        sentence=f'select "{'åŒºåŸŸ' if area_list is not None else 'æ ¡å'}", count(*) from teacher_data_0_{year} where "{'åŒºåŸŸ' if area_list is not None else 'æ ¡å'}" in ({', '.join([f'"{location}"' for location in (area_list if area_list is not None else school_list)])}){f' and "ä»»æ•™å­¦æ®µ" = "{period}" ' if period is not None else ' '}group by "{'åŒºåŸŸ' if area_list is not None else 'æ ¡å'}"'
    )

    for item in discipline_detail_list:
        df1[item[1]][item[0]] = item[2]

        df2_values_sum[item[1]][item[0]] = round(
            number=100 * float(item[2] / list(x[1] for x in count_list if x[0] == item[1])[0]),
            ndigits=1
        )

    df1 = convert_dict_to_dataframe(d=df1)
    df1 = df1.reindex(columns=get_discipline_list())
    df1.fillna(value=0, inplace=True)
    container.add_dataframe(name="discipline_and_location", df=df1)

    df2 = convert_dict_to_dataframe(d=df2_values_sum)
    df2 = df2.reindex(columns=get_discipline_list())
    df2.fillna(value=0, inplace=True)
    df2 = df2.loc[:, ~(df2 == 0).all()]
    container.add_dataframe(name="discipline_percentage_and_location", df=df2)

    return container


def get_1_year_and_multi_areas_or_schools_teacher_0_grad_school_level_dataframe(year: str,
                                                                                area_list: list[str] = None,
                                                                                school_list: list[str] = None,
                                                                                period: str = None) -> DataFrameContainer:
    """
    æ ¹æ®èŒƒå›´åˆ—è¡¨ç”Ÿæˆæ¯•ä¸šé™¢æ ¡ç±»å‹äººæ•°ç»Ÿè®¡dataframeï¼Œæ”¾ç½®åœ¨containerä¸­\n
    grad_school_id_and_location: æ‰€æœ‰æ•°æ®ï¼Œåˆ—ä¸ºæ¯•ä¸šé™¢æ ¡idï¼Œè¡Œä¸ºèŒƒå›´\n
    grad_school_kind_and_location: åˆ†ç±»æ•°æ®ï¼Œåˆ—ä¸ºæ¯•ä¸šé™¢æ ¡çº§åˆ«ï¼Œè¡Œä¸ºèŒƒå›´\n
    grad_school_percentage_and_location: æ‰€æœ‰å­¦ç§‘å èŒƒå›´å æ¯”ï¼Œåˆ—ä¸ºæ¯•ä¸šé™¢æ ¡çº§åˆ«ï¼Œè¡Œä¸ºèŒƒå›´
    :param year: æŸ¥è¯¢çš„å¹´ä»½
    :param area_list: æŸ¥è¯¢çš„ç‰‡é•‡åˆ—è¡¨
    :param school_list: æŸ¥è¯¢çš„å­¦æ ¡åˆ—è¡¨
    :param period: ä»»æ•™å­¦æ®µ
    :return: DataFrameContainerï¼ŒåŒ…å«è‹¥å¹²ä¸ªdataframe
    """
    container = DataFrameContainer()

    df0 = {}  # ä½¿ç”¨åµŒå¥—å­—å…¸ä¿å­˜æ•°æ®ï¼Œå¤–å±‚ä¸ºå¹´ä»½è¡Œï¼Œå†…å±‚ä¸ºå­¦å†åˆ—
    df0.update({location: {} for location in (area_list if area_list is not None else school_list)})

    grad_school_id_list = []

    query_parts = []
    for location in (area_list if area_list is not None else school_list):
        query_part = f'select "{location}", "å‚åŠ å·¥ä½œå‰æ¯•ä¸šé™¢æ ¡ä»£ç " from teacher_data_0_{year} where "{'åŒºåŸŸ' if area_list is not None else 'æ ¡å'}" = "{location}"{f' and "ä»»æ•™å­¦æ®µ" = "{period}" ' if period is not None else ' '}and "å‚åŠ å·¥ä½œå‰å­¦å†" in ("æœ¬ç§‘", "ç¡•å£«ç ”ç©¶ç”Ÿ", "åšå£«ç ”ç©¶ç”Ÿ")'
        query_parts.append(query_part)

    final_query = " union all ".join(query_parts)

    grad_school_id_list.extend(
        item for item in execute_sql_sentence(
            sentence=final_query
        )
    )

    count_dict = dict(
        execute_sql_sentence(
            sentence=f'select "{'åŒºåŸŸ' if area_list is not None else 'æ ¡å'}", count(*) from teacher_data_0_{year} where "{'åŒºåŸŸ' if area_list is not None else 'æ ¡å'}" in ({', '.join([f'"{location}"' for location in (area_list if area_list is not None else school_list)])}){f' and "ä»»æ•™å­¦æ®µ" = "{period}" ' if period is not None else ' '}group by "{'åŒºåŸŸ' if area_list is not None else 'æ ¡å'}"'
        )
    )

    for item in grad_school_id_list:
        if item[1] not in df0[item[0]].keys():
            df0[item[0]][item[1]] = 1
        else:
            df0[item[0]][item[1]] += 1

    df1 = convert_dict_to_dataframe(d=df0)
    df1.fillna(value=0, inplace=True)
    container.add_dataframe(name="grad_school_id_and_location", df=df1)

    df2 = {}
    df3 = {}
    for location in (area_list if area_list is not None else school_list):
        df2[location] = {item: 0. for item in ["985é™¢æ ¡", "å›½ä¼˜è®¡åˆ’é™¢æ ¡", "éƒ¨å±å¸ˆèŒƒé™¢æ ¡", "211é™¢æ ¡", "å…¶ä»–é™¢æ ¡"]}
        df3[location] = {item: 0. for item in ["985é™¢æ ¡", "å›½ä¼˜è®¡åˆ’é™¢æ ¡", "éƒ¨å±å¸ˆèŒƒé™¢æ ¡", "211é™¢æ ¡", "å…¶ä»–é™¢æ ¡"]}

    for item in grad_school_id_list:
        for kind in distinguish_school_id(school_id=item[1], label_length="long"):
            df2[item[0]][kind] += 1

    for location, item in df2.items():
        for key, value in item.items():
            if location in count_dict.keys():
                df3[location][key] = round(
                    number=100 * float(value / count_dict[location]),
                    ndigits=1
                )

    df2 = convert_dict_to_dataframe(d=df2)
    df2.fillna(value=0, inplace=True)
    df2 = df2.loc[:, ~(df2 == 0).all()]  # åˆ é™¤å…¨ä¸º0çš„åˆ—
    container.add_dataframe(name="grad_school_kind_and_location", df=df2)

    df3 = convert_dict_to_dataframe(d=df3)
    df3.fillna(value=0, inplace=True)
    df3 = df3.loc[:, ~(df3 == 0).all()]  # åˆ é™¤å…¨ä¸º0çš„åˆ—
    container.add_dataframe(name="grad_school_percentage_and_location", df=df3)

    return container


if __name__ == '__main__':
    container1 = get_1_year_and_multi_areas_or_schools_teacher_0_age_dataframe(year="2024",
                                                                               school_list=["å¹¿å·å¸‚åŸ¹è‹±ä¸­å­¦",
                                                                                            "å¹¿å·å¸‚å®éªŒå¤–è¯­å­¦æ ¡"])
    print(container1.get_dataframe("age_and_location"))
